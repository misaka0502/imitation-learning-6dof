{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import wandb as wb\n",
    "import imageio\n",
    "from io import BytesIO\n",
    "import pickle\n",
    "import zarr\n",
    "from pathlib import Path\n",
    "import os\n",
    "import random\n",
    "\n",
    "from src.codecs.imagecodecs import Jpeg2k, register_codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_codecs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gif_or_mp4(np_images, filename, fps=10):\n",
    "    # duration = 1000 / fps\n",
    "    with imageio.get_writer(filename, fps=fps) as writer:\n",
    "        for img in tqdm(np_images):\n",
    "            writer.append_data(img)\n",
    "    print(f\"File saved as {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_dir = Path(os.environ.get(\"FURNITURE_DATA_DIR\", \"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_zarr = zarr.open(\n",
    "    \"/data/scratch/ankile/furniture-data-old/data/processed/sim/image_small/one_leg/data.zarr\",\n",
    "    mode=\"r\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_zarr[\"color_image1\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(370234, 224, 224, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_zarr[\"color_image1\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_compressor = Jpeg2k(level=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_store = zarr.open(\n",
    "    \"/data/scratch/ankile/furniture-data-old/data/processed/sim/image_small/one_leg/data_compressed.zarr\",\n",
    "    mode=\"w\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = output_store.require_dataset(\n",
    "    name=\"color_image1\",\n",
    "    shape=(10_000,) + old_zarr[\"color_image1\"].shape[1:],\n",
    "    chunks=(224, 224, 3),\n",
    "    compressor=image_compressor,\n",
    "    dtype=np.uint8,\n",
    ")\n",
    "\n",
    "# for i in tqdm(range(len(old_zarr[\"color_image1\"]))):\n",
    "output_store[\"color_image1\"][:] = old_zarr[\"color_image1\"][:10_000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at the compressed data to verify that it looks alright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = zarr.open(\n",
    "    \"/data/scratch/ankile/furniture-data-old/data/processed/sim/image_small/one_leg/data_compressed.zarr\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the current image data file we're using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = data_base_dir / \"processed/sim/image_small/one_leg/data.zarr\"\n",
    "\n",
    "store = zarr.open(datapath, mode=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((370234, 224, 224, 3), (1, 224, 224, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store[\"color_image1\"].shape, store[\"color_image1\"].chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.730583552"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the storage size of the dataset in GB\n",
    "store[\"color_image1\"].nbytes / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 17987/23140 [35:23<10:08,  8.47it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Time how long it takes to iterate through the dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(store[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor_image1\u001b[39m\u001b[38;5;124m\"\u001b[39m]), \u001b[38;5;241m16\u001b[39m)):\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mstore\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolor_image1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/core.py:844\u001b[0m, in \u001b[0;36mArray.__getitem__\u001b[0;34m(self, selection)\u001b[0m\n\u001b[1;32m    842\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_orthogonal_selection(pure_selection, fields\u001b[38;5;241m=\u001b[39mfields)\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 844\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_basic_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpure_selection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/core.py:970\u001b[0m, in \u001b[0;36mArray.get_basic_selection\u001b[0;34m(self, selection, out, fields)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_basic_selection_zd(selection\u001b[38;5;241m=\u001b[39mselection, out\u001b[38;5;241m=\u001b[39mout, fields\u001b[38;5;241m=\u001b[39mfields)\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_basic_selection_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/core.py:1012\u001b[0m, in \u001b[0;36mArray._get_basic_selection_nd\u001b[0;34m(self, selection, out, fields)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_basic_selection_nd\u001b[39m(\u001b[38;5;28mself\u001b[39m, selection, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, fields\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1007\u001b[0m     \u001b[38;5;66;03m# implementation of basic selection for array with at least one dimension\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m \n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;66;03m# setup indexer\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m BasicIndexer(selection, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1012\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/core.py:1388\u001b[0m, in \u001b[0;36mArray._get_selection\u001b[0;34m(self, indexer, out, fields)\u001b[0m\n\u001b[1;32m   1385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m math\u001b[38;5;241m.\u001b[39mprod(out_shape) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1386\u001b[0m     \u001b[38;5;66;03m# allow storage to get multiple items at once\u001b[39;00m\n\u001b[1;32m   1387\u001b[0m     lchunk_coords, lchunk_selection, lout_selection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mindexer)\n\u001b[0;32m-> 1388\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chunk_getitems\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlchunk_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlchunk_selection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlout_selection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1395\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mshape:\n\u001b[1;32m   1397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/core.py:2224\u001b[0m, in \u001b[0;36mArray._chunk_getitems\u001b[0;34m(self, lchunk_coords, lchunk_selection, out, lout_selection, drop_axes, fields)\u001b[0m\n\u001b[1;32m   2222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_meta_array, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m   2223\u001b[0m         contexts \u001b[38;5;241m=\u001b[39m ConstantMap(ckeys, constant\u001b[38;5;241m=\u001b[39mContext(meta_array\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_meta_array))\n\u001b[0;32m-> 2224\u001b[0m     cdatas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2226\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ckey, chunk_select, out_select \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ckeys, lchunk_selection, lout_selection):\n\u001b[1;32m   2227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ckey \u001b[38;5;129;01min\u001b[39;00m cdatas:\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/_storage/store.py:160\u001b[0m, in \u001b[0;36mBaseStore.getitems\u001b[0;34m(self, keys, contexts)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetitems\u001b[39m(\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m, keys: Sequence[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39m, contexts: Mapping[\u001b[38;5;28mstr\u001b[39m, Context]\n\u001b[1;32m    137\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Mapping[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m    138\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieve data from multiple keys.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m    keys and/or to utilize the contexts.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: \u001b[38;5;28mself\u001b[39m[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m keys \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/_storage/store.py:160\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetitems\u001b[39m(\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m, keys: Sequence[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39m, contexts: Mapping[\u001b[38;5;28mstr\u001b[39m, Context]\n\u001b[1;32m    137\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Mapping[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m    138\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieve data from multiple keys.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m    keys and/or to utilize the contexts.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m keys \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/storage.py:1111\u001b[0m, in \u001b[0;36mDirectoryStore.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1109\u001b[0m filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath, key)\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(filepath):\n\u001b[0;32m-> 1111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/storage.py:1085\u001b[0m, in \u001b[0;36mDirectoryStore._fromfile\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fromfile\u001b[39m(fn):\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read data from a file\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m \n\u001b[1;32m   1075\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;124;03m    file reading logic.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Time how long it takes to iterate through the dataset\n",
    "for i in tqdm(range(0, len(store[\"color_image1\"]), 16)):\n",
    "    store[\"color_image1\"][i : i + 16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test different chunking strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPEG compression with one image per chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = zarr.open(\n",
    "    \"/data/scratch/ankile/tmp-compression-test/data_chunk_1_jpeg.zarr\",\n",
    "    mode=\"w\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = output1.require_dataset(\n",
    "    name=\"color_image1\",\n",
    "    shape=(10_000,) + store[\"color_image1\"].shape[1:],\n",
    "    chunks=(1, 224, 224, 3),\n",
    "    compressor=image_compressor,\n",
    "    dtype=np.uint8,\n",
    ")\n",
    "\n",
    "output1[\"color_image1\"][:] = store[\"color_image1\"][:10_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time how long it takes to do 10_000 random reads\n",
    "random_reads = random.sample(range(0, 10_000), 10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(random_reads):\n",
    "    output1[\"color_image1\"][i : i + 16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default compression with 10 images per chunk    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = zarr.open(\n",
    "    \"/data/scratch/ankile/tmp-compression-test/data_chunk_10_default.zarr\",\n",
    "    mode=\"w\",\n",
    ")\n",
    "_ = output2.require_dataset(\n",
    "    name=\"color_image1\",\n",
    "    shape=(50_000,) + store[\"color_image1\"].shape[1:],\n",
    "    chunks=(10, 224, 224, 3),\n",
    "    # compressor=image_compressor,\n",
    "    dtype=np.uint8,\n",
    ")\n",
    "\n",
    "output2[\"color_image1\"][:] = store[\"color_image1\"][:50_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:20<00:00, 482.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# Time how long it takes to iterate through the dataset\n",
    "for i in tqdm(random_reads):\n",
    "    output2[\"color_image1\"][i : i + 16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default compression with 100 images per chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output3 = zarr.open(\n",
    "    \"/data/scratch/ankile/tmp-compression-test/data_chunk_100_default.zarr\",\n",
    "    mode=\"w\",\n",
    ")\n",
    "_ = output3.require_dataset(\n",
    "    name=\"color_image1\",\n",
    "    shape=(50_000,) + store[\"color_image1\"].shape[1:],\n",
    "    chunks=(100, 224, 224, 3),\n",
    "    # compressor=image_compressor,\n",
    "    dtype=np.uint8,\n",
    ")\n",
    "\n",
    "output3[\"color_image1\"][:] = store[\"color_image1\"][:50_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:30<00:00, 333.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# Time how long it takes to iterate through the dataset\n",
    "for i in tqdm(random_reads):\n",
    "    output3[\"color_image1\"][i : i + 16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default compression with 32 images per chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output4 = zarr.open(\n",
    "    \"/data/scratch/ankile/tmp-compression-test/data_chunk_32_default.zarr\",\n",
    "    mode=\"w\",\n",
    ")\n",
    "_ = output4.require_dataset(\n",
    "    name=\"color_image1\",\n",
    "    shape=(50_000,) + store[\"color_image1\"].shape[1:],\n",
    "    chunks=(32, 224, 224, 3),\n",
    "    # compressor=image_compressor,\n",
    "    dtype=np.uint8,\n",
    ")\n",
    "\n",
    "output4[\"color_image1\"][:] = store[\"color_image1\"][:50_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:20<00:00, 482.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# Time how long it takes to iterate through the dataset\n",
    "for i in tqdm(random_reads):\n",
    "    output4[\"color_image1\"][i : i + 16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a copy of the original data file with chunksize 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdatapath = data_base_dir / \"processed/sim/image_small/one_leg/data_chunks_32.zarr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color_image1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 6/75 [02:31<29:05, 25.29s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 17\u001b[0m\n\u001b[1;32m      8\u001b[0m _ \u001b[38;5;241m=\u001b[39m output_store\u001b[38;5;241m.\u001b[39mrequire_dataset(\n\u001b[1;32m      9\u001b[0m     name\u001b[38;5;241m=\u001b[39mkey,\n\u001b[1;32m     10\u001b[0m     shape\u001b[38;5;241m=\u001b[39mstore[key]\u001b[38;5;241m.\u001b[39mshape,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mstore[key]\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(store[key]), \u001b[38;5;241m5_000\u001b[39m)):\n\u001b[0;32m---> 17\u001b[0m     \u001b[43moutput_store\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5_000\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m store[key][i : i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m5_000\u001b[39m]\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/core.py:1497\u001b[0m, in \u001b[0;36mArray.__setitem__\u001b[0;34m(self, selection, value)\u001b[0m\n\u001b[1;32m   1495\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_orthogonal_selection(pure_selection, value, fields\u001b[38;5;241m=\u001b[39mfields)\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1497\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_basic_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpure_selection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/core.py:1593\u001b[0m, in \u001b[0;36mArray.set_basic_selection\u001b[0;34m(self, selection, value, fields)\u001b[0m\n\u001b[1;32m   1591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_basic_selection_zd(selection, value, fields\u001b[38;5;241m=\u001b[39mfields)\n\u001b[1;32m   1592\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1593\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_basic_selection_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/core.py:1983\u001b[0m, in \u001b[0;36mArray._set_basic_selection_nd\u001b[0;34m(self, selection, value, fields)\u001b[0m\n\u001b[1;32m   1977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_basic_selection_nd\u001b[39m(\u001b[38;5;28mself\u001b[39m, selection, value, fields\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1978\u001b[0m     \u001b[38;5;66;03m# implementation of __setitem__ for array with at least one dimension\u001b[39;00m\n\u001b[1;32m   1979\u001b[0m \n\u001b[1;32m   1980\u001b[0m     \u001b[38;5;66;03m# setup indexer\u001b[39;00m\n\u001b[1;32m   1981\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m BasicIndexer(selection, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1983\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/core.py:2038\u001b[0m, in \u001b[0;36mArray._set_selection\u001b[0;34m(self, indexer, value, fields)\u001b[0m\n\u001b[1;32m   2035\u001b[0m                 chunk_value \u001b[38;5;241m=\u001b[39m chunk_value[item]\n\u001b[1;32m   2037\u001b[0m         \u001b[38;5;66;03m# put data\u001b[39;00m\n\u001b[0;32m-> 2038\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chunk_setitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_coords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_selection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2039\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2040\u001b[0m     lchunk_coords, lchunk_selection, lout_selection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mindexer)\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/core.py:2304\u001b[0m, in \u001b[0;36mArray._chunk_setitem\u001b[0;34m(self, chunk_coords, chunk_selection, value, fields)\u001b[0m\n\u001b[1;32m   2301\u001b[0m     lock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_synchronizer[ckey]\n\u001b[1;32m   2303\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m lock:\n\u001b[0;32m-> 2304\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chunk_setitem_nosync\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_coords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_selection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/core.py:2314\u001b[0m, in \u001b[0;36mArray._chunk_setitem_nosync\u001b[0;34m(self, chunk_coords, chunk_selection, value, fields)\u001b[0m\n\u001b[1;32m   2312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chunk_delitem(ckey)\n\u001b[1;32m   2313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2314\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_store\u001b[49m\u001b[43m[\u001b[49m\u001b[43mckey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_chunk(cdata)\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/storage.py:1144\u001b[0m, in \u001b[0;36mDirectoryStore.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1142\u001b[0m temp_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_path, temp_name)\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1144\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;66;03m# move temporary file into place;\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;66;03m# make several attempts at writing the temporary file to get past\u001b[39;00m\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;66;03m# potential antivirus file locking issues\u001b[39;00m\n\u001b[1;32m   1149\u001b[0m     retry_call(os\u001b[38;5;241m.\u001b[39mreplace, (temp_path, file_path), exceptions\u001b[38;5;241m=\u001b[39m(\u001b[38;5;167;01mPermissionError\u001b[39;00m,))\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/storage.py:1105\u001b[0m, in \u001b[0;36mDirectoryStore._tofile\u001b[0;34m(a, fn)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Write data to a file\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \n\u001b[1;32m   1092\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;124;03mfile writing logic.\u001b[39;00m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fn, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m-> 1105\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(a)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Make a new dataset with the same data but different chunking\n",
    "output_store = zarr.open(outdatapath, mode=\"w\")\n",
    "\n",
    "for key in store.keys():\n",
    "    print(key)\n",
    "    _ = output_store.require_dataset(\n",
    "        name=key,\n",
    "        shape=store[key].shape,\n",
    "        chunks=(32,) + store[key].chunks[1:],\n",
    "        # compressor=image_compressor,\n",
    "        dtype=store[key].dtype,\n",
    "    )\n",
    "\n",
    "    for i in tqdm(range(0, len(store[key]), 5_000)):\n",
    "        output_store[key][i : i + 5_000] = store[key][i : i + 5_000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the new, full dataset with chunksize 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath32 = data_base_dir / \"processed/sim/image_small/one_leg/data_batch_32.zarr\"\n",
    "\n",
    "store32 = zarr.open(datapath32, mode=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 2640/10000 [00:37<01:45, 69.77it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(random_reads):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mstore32\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolor_image1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[i : i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m16\u001b[39m]\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/hierarchy.py:462\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    460\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_item_path(item)\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m contains_array(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store, path):\n\u001b[0;32m--> 462\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mArray\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mread_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chunk_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynchronizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_synchronizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzarr_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeta_array\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_meta_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m contains_group(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store, path, explicit_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Group(\n\u001b[1;32m    474\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store,\n\u001b[1;32m    475\u001b[0m         read_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_only,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    481\u001b[0m         meta_array\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_meta_array,\n\u001b[1;32m    482\u001b[0m     )\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/core.py:224\u001b[0m, in \u001b[0;36mArray.__init__\u001b[0;34m(self, store, path, read_only, chunk_store, synchronizer, cache_metadata, cache_attrs, partial_decompress, write_empty_chunks, zarr_version, meta_array)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata_key_suffix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hierarchy_metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata_key_suffix\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m# initialize metadata\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# initialize attributes\u001b[39;00m\n\u001b[1;32m    227\u001b[0m akey \u001b[38;5;241m=\u001b[39m _prefix_to_attrs_key(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key_prefix)\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/core.py:243\u001b[0m, in \u001b[0;36mArray._load_metadata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"(Re)load metadata from store.\"\"\"\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_synchronizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 243\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_metadata_nosync\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    245\u001b[0m     mkey \u001b[38;5;241m=\u001b[39m _prefix_to_array_key(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key_prefix)\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/core.py:252\u001b[0m, in \u001b[0;36mArray._load_metadata_nosync\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m     mkey \u001b[38;5;241m=\u001b[39m _prefix_to_array_key(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key_prefix)\n\u001b[0;32m--> 252\u001b[0m     meta_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ArrayNotFoundError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path)\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/storage.py:1111\u001b[0m, in \u001b[0;36mDirectoryStore.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1109\u001b[0m filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath, key)\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(filepath):\n\u001b[0;32m-> 1111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/storage.py:1085\u001b[0m, in \u001b[0;36mDirectoryStore._fromfile\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fromfile\u001b[39m(fn):\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read data from a file\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m \n\u001b[1;32m   1075\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;124;03m    file reading logic.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm(random_reads):\n",
    "    store32[\"color_image1\"][i : i + 16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check compression strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import wandb as wb\n",
    "import imageio\n",
    "from io import BytesIO\n",
    "import pickle\n",
    "import zarr\n",
    "from pathlib import Path\n",
    "import os\n",
    "import random\n",
    "\n",
    "from src.codecs.imagecodecs import Jpeg2k, register_codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_dir = Path(os.environ.get(\"FURNITURE_DATA_DIR\", \"data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the current image data file we're using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = data_base_dir / \"processed/sim/image_small/one_leg/data.zarr\"\n",
    "\n",
    "store = zarr.open(datapath, mode=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((370234, 224, 224, 3), (1, 224, 224, 3))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "store[\"color_image1\"].shape, store[\"color_image1\"].chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.730583552"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the storage size of the dataset in GB\n",
    "store[\"color_image1\"].nbytes / 1e9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a one-off conversion of a dataset with chunksize 1 to 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = data_base_dir / \"processed/sim/image_small/one_leg/data_batch_32.zarr\"\n",
    "\n",
    "store = zarr.open(datapath, mode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z.create_dataset(\n",
    "#     \"reward\",\n",
    "#     shape=(0,),\n",
    "#     dtype=np.float32,\n",
    "#     chunks=(chunksize,),\n",
    "# )\n",
    "# z.create_dataset(\n",
    "#     \"skill\",\n",
    "#     shape=(0,),\n",
    "#     dtype=np.float32,\n",
    "#     chunks=(chunksize,),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3696 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3696/3696 [58:34<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "store.create_dataset(\n",
    "    \"reward\",\n",
    "    shape=store[\"reward_old\"].shape,\n",
    "    dtype=np.int8,\n",
    "    chunks=(100,),\n",
    ")\n",
    "\n",
    "# Iterate over the dataset and copy over\n",
    "for i in tqdm(range(0, store[\"reward_old\"].shape[0], 100)):\n",
    "    store[\"reward\"][i : i + 100] = store[\"reward_old\"][i : i + 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3696/3696 [52:59<00:00,  1.16it/s]\n"
     ]
    }
   ],
   "source": [
    "store.create_dataset(\n",
    "    \"skill\",\n",
    "    shape=store[\"skill_old\"].shape,\n",
    "    dtype=np.int8,\n",
    "    chunks=(100,),\n",
    ")\n",
    "\n",
    "# Iterate over the dataset and copy over\n",
    "for i in tqdm(range(0, store[\"skill_old\"].shape[0], 100)):\n",
    "    store[\"skill\"][i : i + 100] = store[\"skill_old\"][i : i + 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run comparisons fo different chunking strategies and compression schemes\n",
    "\n",
    "Read and write speeds of the data is incredibly slow now, how can we recitfy this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "from pathlib import Path\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from numcodecs import Blosc, blosc\n",
    "from glob import glob\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['action',\n",
       " 'color_image1',\n",
       " 'color_image2',\n",
       " 'episode_ends',\n",
       " 'feature',\n",
       " 'furniture',\n",
       " 'parts_poses',\n",
       " 'pickle_file',\n",
       " 'reward',\n",
       " 'robot_state',\n",
       " 'skill',\n",
       " 'success']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get some data\n",
    "data_base_dir = Path(os.environ[\"DATA_DIR_PROCESSED\"])\n",
    "zarr_path = data_base_dir / \"processed\" / \"sim/lamp/scripted/low/success.zarr\"\n",
    "\n",
    "source = zarr.open(\n",
    "    zarr_path,\n",
    "    mode=\"r\",\n",
    ")\n",
    "\n",
    "list(source.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images into memory\n",
    "images = source[\"color_image2\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'179,739'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{images.shape[0]:,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 179739/179739 [12:48<00:00, 233.95it/s]\n",
      "100%|██████████| 180/180 [11:04<00:00,  3.69s/it]\n",
      "100%|██████████| 18/18 [11:05<00:00, 36.98s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create a new dataset\n",
    "target = zarr.open(\n",
    "    \"tmp/uncompressed_chunks_1.zarr\",\n",
    "    mode=\"w\",\n",
    ")\n",
    "\n",
    "# Create the dataset\n",
    "target.create_dataset(\n",
    "    \"color_image2\",\n",
    "    shape=images.shape,\n",
    "    chunks=(1,) + images.shape[1:],\n",
    "    # compressor=image_compressor,\n",
    "    dtype=np.uint8,\n",
    ")\n",
    "\n",
    "# Iterate over the dataset and copy over one by one\n",
    "for i in tqdm(range(0, images.shape[0], 1)):\n",
    "    target[\"color_image2\"][i : i + 1] = images[i : i + 1]\n",
    "\n",
    "# Iterate over the dataset and copy over 1000 at a time\n",
    "for i in tqdm(range(0, images.shape[0], 1000)):\n",
    "    target[\"color_image2\"][i : i + 1000] = images[i : i + 1000]\n",
    "\n",
    "# Iterate over the dataset and copy over 10_000 at a time\n",
    "for i in tqdm(range(0, images.shape[0], 10_000)):\n",
    "    target[\"color_image2\"][i : i + 10_000] = images[i : i + 10_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1798/1798 [02:16<00:00, 13.14it/s]\n",
      "100%|██████████| 180/180 [02:18<00:00,  1.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a new dataset\n",
    "target = zarr.open(\n",
    "    \"tmp/uncompressed_chunks_100.zarr\",\n",
    "    mode=\"w\",\n",
    ")\n",
    "\n",
    "# Create the dataset\n",
    "target.create_dataset(\n",
    "    \"color_image2\",\n",
    "    shape=images.shape,\n",
    "    chunks=(100,) + images.shape[1:],\n",
    "    # compressor=image_compressor,\n",
    "    dtype=np.uint8,\n",
    ")\n",
    "\n",
    "# Iterate over the dataset and copy over one by one\n",
    "for i in tqdm(range(0, images.shape[0], 100)):\n",
    "    target[\"color_image2\"][i : i + 100] = images[i : i + 100]\n",
    "\n",
    "# Iterate over the dataset and copy over 1000 at a time\n",
    "for i in tqdm(range(0, images.shape[0], 1000)):\n",
    "    target[\"color_image2\"][i : i + 1000] = images[i : i + 1000]\n",
    "\n",
    "# # Iterate over the dataset and copy over 10_000 at a time\n",
    "# for i in tqdm(range(0, images.shape[0], 10_000)):\n",
    "#     target[\"color_image2\"][i : i + 10_000] = images[i : i + 10_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [02:09<00:00,  1.39it/s]\n",
      "100%|██████████| 36/36 [02:10<00:00,  3.61s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create a new dataset\n",
    "target = zarr.open(\n",
    "    \"tmp/uncompressed_chunks_1000.zarr\",\n",
    "    mode=\"w\",\n",
    ")\n",
    "\n",
    "# Create the dataset\n",
    "target.create_dataset(\n",
    "    \"color_image2\",\n",
    "    shape=images.shape,\n",
    "    chunks=(1000,) + images.shape[1:],\n",
    "    # compressor=image_compressor,\n",
    "    dtype=np.uint8,\n",
    ")\n",
    "\n",
    "# Iterate over the dataset and copy over one by one\n",
    "for i in tqdm(range(0, images.shape[0], 1000)):\n",
    "    target[\"color_image2\"][i : i + 1000] = images[i : i + 1000]\n",
    "\n",
    "# Iterate over the dataset and copy over 1000 at a time\n",
    "for i in tqdm(range(0, images.shape[0], 5000)):\n",
    "    target[\"color_image2\"][i : i + 5000] = images[i : i + 5000]\n",
    "\n",
    "# # Iterate over the dataset and copy over 10_000 at a time\n",
    "# for i in tqdm(range(0, images.shape[0], 10_000)):\n",
    "#     target[\"color_image2\"][i : i + 10_000] = images[i : i + 10_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1798/1798 [02:16<00:00, 13.20it/s]\n",
      "100%|██████████| 180/180 [02:15<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "compressor = Blosc(cname=\"lz4\", clevel=5)\n",
    "\n",
    "# Create a new dataset\n",
    "target = zarr.open(\n",
    "    \"tmp/compressed_chunks_100_level_5.zarr\",\n",
    "    mode=\"w\",\n",
    ")\n",
    "\n",
    "# Create the dataset\n",
    "target.create_dataset(\n",
    "    \"color_image2\",\n",
    "    shape=images.shape,\n",
    "    chunks=(100,) + images.shape[1:],\n",
    "    compressor=compressor,\n",
    "    dtype=np.uint8,\n",
    ")\n",
    "\n",
    "# Iterate over the dataset and copy over one by one\n",
    "for i in tqdm(range(0, images.shape[0], 100)):\n",
    "    target[\"color_image2\"][i : i + 100] = images[i : i + 100]\n",
    "\n",
    "# Iterate over the dataset and copy over 1000 at a time\n",
    "for i in tqdm(range(0, images.shape[0], 1_000)):\n",
    "    target[\"color_image2\"][i : i + 1_000] = images[i : i + 1_000]\n",
    "\n",
    "# # Iterate over the dataset and copy over 10_000 at a time\n",
    "# for i in tqdm(range(0, images.shape[0], 10_000)):\n",
    "#     target[\"color_image2\"][i : i + 10_000] = images[i : i + 10_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [02:09<00:00,  1.39it/s]\n",
      "100%|██████████| 36/36 [02:10<00:00,  3.64s/it]\n"
     ]
    }
   ],
   "source": [
    "compressor = Blosc(cname=\"lz4\", clevel=5)\n",
    "\n",
    "# Create a new dataset\n",
    "target = zarr.open(\n",
    "    \"tmp/compressed_chunks_1000_level_5.zarr\",\n",
    "    mode=\"w\",\n",
    ")\n",
    "\n",
    "# Create the dataset\n",
    "target.create_dataset(\n",
    "    \"color_image2\",\n",
    "    shape=images.shape,\n",
    "    chunks=(1000,) + images.shape[1:],\n",
    "    compressor=compressor,\n",
    "    dtype=np.uint8,\n",
    ")\n",
    "\n",
    "# Iterate over the dataset and copy over one by one\n",
    "for i in tqdm(range(0, images.shape[0], 1_000)):\n",
    "    target[\"color_image2\"][i : i + 1_000] = images[i : i + 1_000]\n",
    "\n",
    "# Iterate over the dataset and copy over 1000 at a time\n",
    "for i in tqdm(range(0, images.shape[0], 5_000)):\n",
    "    target[\"color_image2\"][i : i + 5_000] = images[i : i + 5_000]\n",
    "\n",
    "# # Iterate over the dataset and copy over 10_000 at a time\n",
    "# for i in tqdm(range(0, images.shape[0], 10_000)):\n",
    "#     target[\"color_image2\"][i : i + 10_000] = images[i : i + 10_000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do similar experiments in the context of the pickle processing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing module 'gym_38' (/data/scratch/ankile/isaacgym/python/isaacgym/_bindings/linux-x86_64/gym_38.so)\n",
      "Setting GYM_USD_PLUG_INFO_PATH to /data/scratch/ankile/isaacgym/python/isaacgym/_bindings/linux-x86_64/usd/plugInfo.json\n"
     ]
    }
   ],
   "source": [
    "from src.data_processing.process_pickles import (\n",
    "    parallel_process_pickle_files,\n",
    "    initialize_zarr_store,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkl_glob = \"/data/scratch-oc40/pulkitag/ankile/furniture-data/raw/sim/square_table/teleop/low/success/*.pkl*\"\n",
    "outpath = \"/data/scratch/ankile/furniture-data/processed/sim/square_table/teleop/low/success_test.zarr\"\n",
    "\n",
    "pickle_paths = [Path(p) for p in glob(pkl_glob, recursive=True)]\n",
    "len(pickle_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pickle files with 16 CPUs, chunksize=1000, noop_threshold=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 50/50 [03:02<00:00,  3.66s/it] \n"
     ]
    }
   ],
   "source": [
    "# Process all pickle files\n",
    "chunksize = 1_000\n",
    "noop_threshold = 0.0\n",
    "# n_cpus = min(os.cpu_count(), 64)\n",
    "n_cpus = 16\n",
    "\n",
    "print(\n",
    "    f\"Processing pickle files with {n_cpus} CPUs, chunksize={chunksize}, noop_threshold={noop_threshold}\"\n",
    ")\n",
    "\n",
    "all_data = parallel_process_pickle_files(pickle_paths, noop_threshold, n_cpus)\n",
    "\n",
    "# Define the full shapes for each dataset\n",
    "full_data_shapes = [\n",
    "    # These are of length: number of timesteps\n",
    "    (\"robot_state\", all_data[\"robot_state\"].shape, np.float32),\n",
    "    (\"color_image1\", all_data[\"color_image1\"].shape, np.uint8),\n",
    "    (\"color_image2\", all_data[\"color_image2\"].shape, np.uint8),\n",
    "    (\"action/delta\", all_data[\"action/delta\"].shape, np.float32),\n",
    "    (\"action/pos\", all_data[\"action/pos\"].shape, np.float32),\n",
    "    (\"skill\", all_data[\"skill\"].shape, np.float32),\n",
    "    (\"reward\", all_data[\"reward\"].shape, np.float32),\n",
    "    (\"parts_poses\", all_data[\"parts_poses\"].shape, np.float32),\n",
    "    # These are of length: number of episodes\n",
    "    (\"episode_ends\", (len(all_data[\"episode_ends\"]),), np.uint32),\n",
    "    (\"furniture\", (len(all_data[\"furniture\"]),), str),\n",
    "    (\"success\", (len(all_data[\"success\"]),), np.uint8),\n",
    "    (\"pickle_file\", (len(all_data[\"pickle_file\"]),), str),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'63,930'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{all_data['color_image1'].shape[0]:,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing data to zarr: color_image2:   9%|▉         | 1/11 [00:34<05:48, 34.85s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m     data \u001b[38;5;241m=\u001b[39m all_data[name]\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m trange(\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(all_data[name]), chunksize, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWriting chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     ):\n\u001b[0;32m---> 13\u001b[0m         \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m all_data[name][i : i \u001b[38;5;241m+\u001b[39m chunksize]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Update final metadata\u001b[39;00m\n\u001b[1;32m     16\u001b[0m z\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_finished\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mastimezone()\u001b[38;5;241m.\u001b[39misoformat()\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/core.py:1497\u001b[0m, in \u001b[0;36mArray.__setitem__\u001b[0;34m(self, selection, value)\u001b[0m\n\u001b[1;32m   1495\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_orthogonal_selection(pure_selection, value, fields\u001b[38;5;241m=\u001b[39mfields)\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1497\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_basic_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpure_selection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/core.py:1593\u001b[0m, in \u001b[0;36mArray.set_basic_selection\u001b[0;34m(self, selection, value, fields)\u001b[0m\n\u001b[1;32m   1591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_basic_selection_zd(selection, value, fields\u001b[38;5;241m=\u001b[39mfields)\n\u001b[1;32m   1592\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1593\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_basic_selection_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/core.py:1983\u001b[0m, in \u001b[0;36mArray._set_basic_selection_nd\u001b[0;34m(self, selection, value, fields)\u001b[0m\n\u001b[1;32m   1977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_basic_selection_nd\u001b[39m(\u001b[38;5;28mself\u001b[39m, selection, value, fields\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1978\u001b[0m     \u001b[38;5;66;03m# implementation of __setitem__ for array with at least one dimension\u001b[39;00m\n\u001b[1;32m   1979\u001b[0m \n\u001b[1;32m   1980\u001b[0m     \u001b[38;5;66;03m# setup indexer\u001b[39;00m\n\u001b[1;32m   1981\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m BasicIndexer(selection, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1983\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/core.py:2038\u001b[0m, in \u001b[0;36mArray._set_selection\u001b[0;34m(self, indexer, value, fields)\u001b[0m\n\u001b[1;32m   2035\u001b[0m                 chunk_value \u001b[38;5;241m=\u001b[39m chunk_value[item]\n\u001b[1;32m   2037\u001b[0m         \u001b[38;5;66;03m# put data\u001b[39;00m\n\u001b[0;32m-> 2038\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chunk_setitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_coords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_selection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2039\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2040\u001b[0m     lchunk_coords, lchunk_selection, lout_selection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mindexer)\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/core.py:2304\u001b[0m, in \u001b[0;36mArray._chunk_setitem\u001b[0;34m(self, chunk_coords, chunk_selection, value, fields)\u001b[0m\n\u001b[1;32m   2301\u001b[0m     lock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_synchronizer[ckey]\n\u001b[1;32m   2303\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m lock:\n\u001b[0;32m-> 2304\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chunk_setitem_nosync\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_coords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_selection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/core.py:2314\u001b[0m, in \u001b[0;36mArray._chunk_setitem_nosync\u001b[0;34m(self, chunk_coords, chunk_selection, value, fields)\u001b[0m\n\u001b[1;32m   2312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chunk_delitem(ckey)\n\u001b[1;32m   2313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2314\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_store[ckey] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/site-packages/zarr/core.py:2444\u001b[0m, in \u001b[0;36mArray._encode_chunk\u001b[0;34m(self, chunk)\u001b[0m\n\u001b[1;32m   2442\u001b[0m \u001b[38;5;66;03m# compress\u001b[39;00m\n\u001b[1;32m   2443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compressor:\n\u001b[0;32m-> 2444\u001b[0m     cdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2445\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2446\u001b[0m     cdata \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32mnumcodecs/blosc.pyx:560\u001b[0m, in \u001b[0;36mnumcodecs.blosc.Blosc.encode\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mnumcodecs/blosc.pyx:287\u001b[0m, in \u001b[0;36mnumcodecs.blosc.compress\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/data/scratch/ankile/miniconda3/envs/rlgpu/lib/python3.8/multiprocessing/synchronize.py:97\u001b[0m, in \u001b[0;36mSemLock.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_semlock\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_semlock\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getstate__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize Zarr store with full dimensions\n",
    "z = initialize_zarr_store(outpath, full_data_shapes, chunksize=chunksize)\n",
    "\n",
    "# Write the data to the Zarr store\n",
    "it = tqdm(all_data)\n",
    "for name in it:\n",
    "    it.set_description(f\"Writing data to zarr: {name}\")\n",
    "    dataset = z[name]\n",
    "    data = all_data[name]\n",
    "    for i in trange(\n",
    "        0, len(all_data[name]), chunksize, desc=\"Writing chunks\", leave=False\n",
    "    ):\n",
    "        dataset[i : i + chunksize] = all_data[name][i : i + chunksize]\n",
    "\n",
    "# Update final metadata\n",
    "z.attrs[\"time_finished\"] = datetime.now().astimezone().isoformat()\n",
    "z.attrs[\"noop_threshold\"] = noop_threshold\n",
    "z.attrs[\"chunksize\"] = chunksize\n",
    "z.attrs[\"rotation_mode\"] = \"rot_6d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = Blosc(cname=\"lz4\", clevel=5)\n",
    "\n",
    "# Create a new dataset\n",
    "target = zarr.open(\n",
    "    \"tmp/compressed_chunks_1000_level_5.zarr\",\n",
    "    mode=\"w\",\n",
    ")\n",
    "\n",
    "# Create the dataset\n",
    "target.create_dataset(\n",
    "    \"color_image2\",\n",
    "    shape=images.shape,\n",
    "    chunks=(1000,) + images.shape[1:],\n",
    "    compressor=compressor,\n",
    "    dtype=np.uint8,\n",
    ")\n",
    "\n",
    "images2 = all_data[\"color_image2\"]\n",
    "\n",
    "# Iterate over the dataset and copy over one by one\n",
    "for i in tqdm(range(0, images.shape[0], chunksize)):\n",
    "    target[\"color_image2\"][i : i + 1] = images2[i : i + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for combining a list of zarr files into a single numpy array in memory for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_zarr_datasets(zarr_paths, keys):\n",
    "    # Initialize dictionary to hold total shapes\n",
    "    total_shapes = {key: 0 for key in keys}\n",
    "    last_episode_end = 0\n",
    "\n",
    "    # First pass to calculate total shapes\n",
    "    for path in zarr_paths:\n",
    "        dataset = zarr.open(path, mode=\"r\")\n",
    "        for key in keys:\n",
    "            data_shape = dataset[key].shape[0]\n",
    "            if key == \"episode_ends\":\n",
    "                total_shapes[key] += data_shape\n",
    "            else:\n",
    "                total_shapes[key] += data_shape\n",
    "\n",
    "    # Preallocate numpy arrays\n",
    "    combined_data = {}\n",
    "    for path in zarr_paths:\n",
    "        dataset = zarr.open(path, mode=\"r\")\n",
    "        for key in keys:\n",
    "            dtype = dataset[key].dtype\n",
    "            if key not in combined_data:\n",
    "                if key == \"episode_ends\":\n",
    "                    combined_data[key] = np.zeros(total_shapes[key], dtype=dtype)\n",
    "                else:\n",
    "                    # Assuming other arrays are 2D, adjust if not\n",
    "                    combined_data[key] = np.zeros(\n",
    "                        (total_shapes[key], *dataset[key].shape[1:]), dtype=dtype\n",
    "                    )\n",
    "\n",
    "    # Current indices for insertion into preallocated arrays\n",
    "    current_indices = {key: 0 for key in keys}\n",
    "\n",
    "    # Second pass to populate arrays\n",
    "    for path in tqdm(zarr_paths, desc=\"Loading zarr files\"):\n",
    "        dataset = zarr.open(path, mode=\"r\")\n",
    "\n",
    "        for key in tqdm(keys, desc=\"Loading data\", position=1):\n",
    "            data = dataset[key][...]\n",
    "            data_length = data.shape[0]\n",
    "\n",
    "            if key == \"episode_ends\":\n",
    "                if last_episode_end != 0:\n",
    "                    data += last_episode_end\n",
    "                last_episode_end = data[-1]\n",
    "\n",
    "            combined_data[key][\n",
    "                current_indices[key] : current_indices[key] + data_length\n",
    "            ] = data\n",
    "            current_indices[key] += data_length\n",
    "\n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading zarr files: 100%|██████████| 2/2 [02:26<00:00, 73.20s/it]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "zarr_paths = [\n",
    "    \"/data/scratch/ankile/furniture-data/processed/sim/round_table/scripted/low/success.zarr\",\n",
    "    \"/data/scratch/ankile/furniture-data/processed/sim/round_table/scripted/med/success.zarr\",\n",
    "]\n",
    "\n",
    "keys = [\n",
    "    \"robot_state\",\n",
    "    \"color_image1\",\n",
    "    \"episode_ends\",\n",
    "]\n",
    "\n",
    "combined_data = combine_zarr_datasets(zarr_paths, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((328332, 16), (328332, 240, 320, 3), (252,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data[\"robot_state\"].shape, combined_data[\"color_image1\"].shape, combined_data[\n",
    "    \"episode_ends\"\n",
    "].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328332"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data[\"episode_ends\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
