{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import furniture_bench\n",
    "import gym\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append('/data/pulkitag/data/anthony/repos/research2/furniture-diffusion')\n",
    "from src.models.vision import get_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup meshcat\n",
    "from sim_web_visualizer.isaac_visualizer_client import create_isaac_visualizer\n",
    "mc_vis = create_isaac_visualizer(port=6000, host=\"localhost\", keep_default_viewer=False, max_env=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test normal env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"FurnitureSim-v0\",\n",
    "    furniture=\"one_leg\",  # Specifies the type of furniture [lamp | square_table | desk | drawer | cabinet | round_table | stool | chair | one_leg].\n",
    "    num_envs=16,  # Number of parallel environments.\n",
    "    resize_img=True,  # If true, images are resized to 224 x 224.\n",
    "    concat_robot_state=True,  # If true, robot state is concatenated to the observation.\n",
    "    headless=True,  # If true, simulation runs without GUI.\n",
    "    compute_device_id=0,\n",
    "    graphics_device_id=0,\n",
    "    init_assembled=False,  # If true, the environment is initialized with assembled furniture.\n",
    "    np_step_out=False,  # If true, env.step() returns Numpy arrays.\n",
    "    channel_first=False,  # If true, images are returned in channel first format.\n",
    "    randomness=\"low\",  # Level of randomness in the environment [low | med | high].\n",
    "    high_random_idx=-1,  # Index of the high randomness level (range: [0-2]). Default -1 will randomly select the index within the range.\n",
    "    save_camera_input=False,  # If true, the initial camera inputs are saved.\n",
    "    record=False,  # If true, videos of the wrist and front cameras' RGB inputs are recorded.\n",
    "    max_env_steps=3000,  # Maximum number of steps per episode.\n",
    "    act_rot_repr=\"quat\",  # Representation of rotation for action space. Options are 'quat' and 'axis'.\n",
    "    mc_vis=mc_vis\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample action\n",
    "action = env.action_space.sample()\n",
    "print(\"Action shape: \", action.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "\n",
    "# Take a step\n",
    "obs, reward, done, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs[\"color_image2\"].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs[\"robot_state\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(250):\n",
    "    # Take a step\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = env.action_space.sample()\n",
    "obs, reward, done, info = env.step(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Feature Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_encoder(\"dinov2-base\")\n",
    "\n",
    "env = gym.make(\n",
    "    \"FurnitureSimFeature-v0\",\n",
    "    furniture=\"one_leg\",  # Specifies the type of furniture [lamp | square_table | desk | drawer | cabinet | round_table | stool | chair | one_leg].\n",
    "    num_envs=4,  # Number of parallel environments.\n",
    "    headless=True,  # If true, simulation runs without GUI.\n",
    "    encoder=encoder,\n",
    "    compute_device_id=0,\n",
    "    graphics_device_id=0,\n",
    "    init_assembled=False,  # If true, the environment is initialized with assembled furniture.\n",
    "    randomness=\"low\",  # Level of randomness in the environment [low | med | high].\n",
    "    high_random_idx=-1,  # Index of the high randomness level (range: [0-2]). Default -1 will randomly select the index within the range.\n",
    "    save_camera_input=False,  # If true, the initial camera inputs are saved.\n",
    "    record=False,  # If true, videos of the wrist and front cameras' RGB inputs are recorded.\n",
    "    max_env_steps=3000,  # Maximum number of steps per episode.\n",
    "    act_rot_repr=\"quat\",  # Representation of rotation for action space. Options are 'quat' and 'axis'.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder(obs[\"color_image2\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_encoder(\"dinov2-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder(torch.zeros(16, 2, 224, 224, 3).reshape(-1, 224, 224, 3)).reshape(\n",
    "    16, 2, -1\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
